---
layout: page
---

You can also check my [Google Scholar
profile](https://scholar.google.com/citations?user=iFRueeoAAAAJ&hl=en&oi=ao)

**2021**

- M. Zeineldeen, A. Glushko, W. Michel, A. Zeyer, R. Schl端ter, and H. Ney.
  [Investigating Methods to Improve Language Model Integration for
  Attention-based Encoder-Decoder ASR
  Models](https://arxiv.org/abs/2104.05544). April, 2021. Submitted to
  Interspeech 2021.

- N. Rossenbach, M. Zeineldeen, B. Hilmes, R. Schl端ter, and H. Ney.
  [Comparing the Benefit of Synthetic Training Data for Various Automatic Speech
  Recognition Architectures](https://arxiv.org/abs/2104.05379). April, 2021.
  Submitted to Interspeech 2021.

**2020**

- M. Zeineldeen, A. Zeyer, W. Zhou, T. Ng, R. Schl端ter, and H. Ney.
[A Systematic Comparison of Grapheme-based vs. Phoneme-based Label Units for Encoder-Decoder-Attention Models](https://arxiv.org/abs/2005.09336). arXiv:2005.09336.

- M. Zeineldeen, A. Zeyer, R. Schl端ter and H. Ney.
[Layer-Normalized LSTM for Hybrid-Hmm and End-To-End ASR](https://www-i6.informatik.rwth-aachen.de/publications/download/1127/Zeineldeen-ICASSP-2020.pdf),
ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP),
Barcelona, Spain, 2020, pp. 7679-7683 [[slides]]({{ site.baseurl }}/pdfs/icassp-2020-presentation.pdf)
